{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fa99d58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fdd22e71c90>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "torch.set_printoptions(edgeitems=2)\n",
    "torch.manual_seed(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd58b8f",
   "metadata": {},
   "source": [
    "## Image and 3D volumetric data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9bfba28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8492e88e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(720, 1280, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_arr = imageio.imread(\"dlwpt-code/data/p1ch4/image-dog/bobby.jpg\")\n",
    "img_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae346de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## converting the img_arr to tensor\n",
    "img = torch.from_numpy(img_arr)\n",
    "##pytorch requires images to be in (channel, height, width) \n",
    "##but ours is (height, width, channel) so we shuffle\n",
    "out = img.permute(2, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "baa7c10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 3\n",
    "batch = torch.zeros(batch_size, 3, 256, 256, dtype=torch.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0d58263",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "data_dir = 'dlwpt-code/data/p1ch4/image-cats/'\n",
    "filenames = [name for name in os.listdir(data_dir)\n",
    "if os.path.splitext(name)[-1] == '.png']\n",
    "for i, filename in enumerate(filenames):\n",
    "    img_arr = imageio.imread(os.path.join(data_dir, filename))\n",
    "    img_t = torch.from_numpy(img_arr)\n",
    "    img_t = img_t.permute(2, 0, 1)\n",
    "    img_t = img_t[:3] # keep only first three channel cause the rest might have extra info like transparency which we dont need\n",
    "    batch[i] = img_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3aeac46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## normalization\n",
    "batch = batch.float()\n",
    "batch /= 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e68e60f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading DICOM (examining files): 1/99 files (1.0%99/99 files (100.0%)\n",
      "  Found 1 correct series.\n",
      "Reading DICOM (loading data): 73/99  (73.799/99  (100.0%)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(99, 512, 512)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for 3d data\n",
    "dir_path = r\"dlwpt-code/data/p1ch4/volumetric-dicom/2-LUNG3.0B70f-04083/\"\n",
    "vol_arr = imageio.volread(dir_path, 'DICOM')\n",
    "vol_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84bd65e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 99, 512, 512])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vol = torch.from_numpy(vol_arr).float()\n",
    "vol = torch.unsqueeze(vol, 0)\n",
    "vol.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d1532c",
   "metadata": {},
   "source": [
    "## CSV data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d88e9eaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7.  ,  0.27,  0.36, ...,  0.45,  8.8 ,  6.  ],\n",
       "       [ 6.3 ,  0.3 ,  0.34, ...,  0.49,  9.5 ,  6.  ],\n",
       "       [ 8.1 ,  0.28,  0.4 , ...,  0.44, 10.1 ,  6.  ],\n",
       "       ...,\n",
       "       [ 6.5 ,  0.24,  0.19, ...,  0.46,  9.4 ,  6.  ],\n",
       "       [ 5.5 ,  0.29,  0.3 , ...,  0.38, 12.8 ,  7.  ],\n",
       "       [ 6.  ,  0.21,  0.38, ...,  0.32, 11.8 ,  6.  ]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## using a csv file\n",
    "import csv\n",
    "wine_path = \"dlwpt-code/data/p1ch4/tabular-wine/winequality-white.csv\"\n",
    "wineq_numpy = np.loadtxt(wine_path, dtype=np.float32, delimiter=\";\", skiprows=1)\n",
    "\n",
    "wineq_numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed4c3189",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4898, 12),\n",
       " ['fixed acidity',\n",
       "  'volatile acidity',\n",
       "  'citric acid',\n",
       "  'residual sugar',\n",
       "  'chlorides',\n",
       "  'free sulfur dioxide',\n",
       "  'total sulfur dioxide',\n",
       "  'density',\n",
       "  'pH',\n",
       "  'sulphates',\n",
       "  'alcohol',\n",
       "  'quality'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_list = next(csv.reader(open(wine_path), delimiter=';'))\n",
    "wineq_numpy.shape, col_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0115d50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4898, 12]), torch.float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wineq = torch.from_numpy(wineq_numpy)\n",
    "wineq.shape, wineq.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "79fc75ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = wineq[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "856af7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = wineq[:, -1].long()\n",
    "#allows us to treat them as labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "035d0673",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.,  ..., 0., 0.],\n",
       "        [0., 0.,  ..., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0.,  ..., 0., 0.],\n",
       "        [0., 0.,  ..., 0., 0.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_onehot = torch.zeros(target.shape[0], 10)\n",
    "target_onehot.scatter_(1, target.unsqueeze(1), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6a356563",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6.8548e+00, 2.7824e-01, 3.3419e-01, 6.3914e+00, 4.5772e-02, 3.5308e+01,\n",
       "        1.3836e+02, 9.9403e-01, 3.1883e+00, 4.8985e-01, 1.0514e+01])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_mean = torch.mean(data, dim=0)\n",
    "data_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ddc39222",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7.1211e-01, 1.0160e-02, 1.4646e-02, 2.5726e+01, 4.7733e-04, 2.8924e+02,\n",
       "        1.8061e+03, 8.9455e-06, 2.2801e-02, 1.3025e-02, 1.5144e+00])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_var = torch.var(data, dim=0)\n",
    "data_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "04fda8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_normalised = (data-data_mean)/torch.sqrt(data_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e8d70c92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.7208e-01, -8.1761e-02,  ..., -3.4915e-01, -1.3930e+00],\n",
       "        [-6.5743e-01,  2.1587e-01,  ...,  1.3422e-03, -8.2419e-01],\n",
       "        ...,\n",
       "        [-1.6054e+00,  1.1666e-01,  ..., -9.6251e-01,  1.8574e+00],\n",
       "        [-1.0129e+00, -6.7703e-01,  ..., -1.4882e+00,  1.0448e+00]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_normalised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0c75b3ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4898]), torch.bool, tensor(20))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_indexes = target <= 3\n",
    "bad_indexes.shape, bad_indexes.dtype, bad_indexes.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "566a0424",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 11])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bad_data = data[bad_indexes]\n",
    "bad_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4506bef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0 fixed acidity          7.60   6.89   6.73\n",
      " 1 volatile acidity       0.33   0.28   0.27\n",
      " 2 citric acid            0.34   0.34   0.33\n",
      " 3 residual sugar         6.39   6.71   5.26\n",
      " 4 chlorides              0.05   0.05   0.04\n",
      " 5 free sulfur dioxide   53.33  35.42  34.55\n",
      " 6 total sulfur dioxide 170.60 141.83 125.25\n",
      " 7 density                0.99   0.99   0.99\n",
      " 8 pH                     3.19   3.18   3.22\n",
      " 9 sulphates              0.47   0.49   0.50\n",
      "10 alcohol               10.34  10.26  11.42\n"
     ]
    }
   ],
   "source": [
    "bad_data = data[target <= 3]\n",
    "mid_data = data[(target > 3) & (target < 7)]\n",
    "good_data = data[target >= 7]\n",
    "\n",
    "bad_mean = torch.mean(bad_data, dim=0)\n",
    "mid_mean = torch.mean(mid_data, dim=0)\n",
    "good_mean = torch.mean(good_data, dim=0)\n",
    "for i, args in enumerate(zip(col_list, bad_mean, mid_mean, good_mean)):\n",
    "    print('{:2} {:20} {:6.2f} {:6.2f} {:6.2f}'.format(i, *args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d1ecbece",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4898]), torch.bool, tensor(2727))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_sulfur_threshold = 141.83\n",
    "total_sulfur_data = data[:,6]\n",
    "predicted_indexes = torch.lt(total_sulfur_data, total_sulfur_threshold)\n",
    "predicted_indexes.shape, predicted_indexes.dtype, predicted_indexes.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "881d5d5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4898]), torch.bool, tensor(3258))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_indexes = target > 5\n",
    "actual_indexes.shape, actual_indexes.dtype, actual_indexes.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "feb30a9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2018, 0.74000733406674, 0.6193984039287906)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_matches = torch.sum(actual_indexes & predicted_indexes).item()\n",
    "n_predicted = torch.sum(predicted_indexes).item()\n",
    "n_actual = torch.sum(actual_indexes).item()\n",
    "n_matches, n_matches / n_predicted, n_matches / n_actual"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5cd268",
   "metadata": {},
   "source": [
    "## Time series data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "699a51a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000e+00, 1.0000e+00,  ..., 1.3000e+01, 1.6000e+01],\n",
       "        [2.0000e+00, 1.0000e+00,  ..., 3.2000e+01, 4.0000e+01],\n",
       "        ...,\n",
       "        [1.7378e+04, 3.1000e+01,  ..., 4.8000e+01, 6.1000e+01],\n",
       "        [1.7379e+04, 3.1000e+01,  ..., 3.7000e+01, 4.9000e+01]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bikes_numpy = np.loadtxt(\"dlwpt-code/data/p1ch4/bike-sharing-dataset/hour-fixed.csv\",\n",
    "                        dtype=np.float32,\n",
    "                        delimiter=\",\",\n",
    "                        skiprows=1,\n",
    "                        converters={1: lambda x: float(x[8:10])}) #last part converts the date string to a number corresponding to day of month\n",
    "\n",
    "bikes = torch.from_numpy(bikes_numpy)\n",
    "bikes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b7198c72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([17520, 17]), (17, 1))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bikes.shape, bikes.stride()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d7b462ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([730, 24, 17]), (408, 17, 1))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we want to make batches of 24 hours each to ensure that we look at bike usage per day\n",
    "# the present data is already hourly so we can make each batch have 24 entries to accomplish this\n",
    "\n",
    "daily_bikes = bikes.view(-1, 24, bikes.shape[1])\n",
    "daily_bikes.shape, daily_bikes.stride()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c9910275",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([730, 17, 24]), (408, 1, 17))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_bikes = daily_bikes.transpose(1, 2)\n",
    "daily_bikes.shape, daily_bikes.stride()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f0a5c389",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 3, 3, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_day = bikes[:24].long()\n",
    "weather_onehot = torch.zeros(first_day.shape[0], 4)\n",
    "first_day[:,9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b0d758ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.],\n",
       "        [0., 1., 0., 0.]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather_onehot.scatter_(\n",
    "dim=1,\n",
    "index=first_day[:,9].unsqueeze(1).long() - 1,\n",
    "value=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3e7da8b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0000,  1.0000,  1.0000,  0.0000,  1.0000,  0.0000,  0.0000,  6.0000,\n",
       "          0.0000,  1.0000,  0.2400,  0.2879,  0.8100,  0.0000,  3.0000, 13.0000,\n",
       "         16.0000,  1.0000,  0.0000,  0.0000,  0.0000]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat((bikes[:24], weather_onehot), 1)[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ddfbafb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([730, 4, 24])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_weather_onehot = torch.zeros(daily_bikes.shape[0], 4,\n",
    "daily_bikes.shape[2])\n",
    "daily_weather_onehot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bc0cc293",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([730, 4, 24])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daily_weather_onehot.scatter_(\n",
    "1, daily_bikes[:,9,:].long().unsqueeze(1) - 1, 1.0)\n",
    "daily_weather_onehot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6a5f221c",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_bikes = torch.cat((daily_bikes, daily_weather_onehot), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "18136983",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_bikes[:, 9, :] = (daily_bikes[:, 9, :] - 1.0) / 3.0 #another way to treat ordinal values by pretendfing they are continuous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f3dbaaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rescaling values\n",
    "temp = daily_bikes[:, 10, :]\n",
    "temp_min = torch.min(temp)\n",
    "temp_max = torch.max(temp)\n",
    "daily_bikes[:, 10, :] = ((daily_bikes[:, 10, :] - temp_min)\n",
    "                            / (temp_max - temp_min)) #mapping in the range [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6776ea36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'temp = daily_bikes[:, 10, :]\\ndaily_bikes[:, 10, :] = ((daily_bikes[:, 10, :] - torch.mean(temp))\\n                        / torch.std(temp))'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''temp = daily_bikes[:, 10, :]\n",
    "daily_bikes[:, 10, :] = ((daily_bikes[:, 10, :] - torch.mean(temp))\n",
    "                        / torch.std(temp))'''\n",
    "# subtracting mean and dividing by std dev. another way to rescale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9122414c",
   "metadata": {},
   "source": [
    "## Text Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5524b6eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dlwpt-code/data/p1ch4/jane-austen/1342-0.txt', encoding='utf8') as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4ea42b3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'at Mr. Darcy, “There is a fine old saying, which everybody here is of'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## since english we use only ascii to reduce the encoding size\n",
    "## also we convert everything to lowercase and remove punctuation etc which aren't relevant to our scenario\n",
    "lines = text.split('\\n')\n",
    "line = lines[800]\n",
    "line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "80688f73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([69, 128])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "letter_t = torch.zeros(len(line), 128) #128 because that is the limit of ASCII\n",
    "letter_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "49d41336",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing non ASCII chars and one hot encoding each letter\n",
    "for i, letter in enumerate(line.lower().strip()):\n",
    "    letter_index = ord(letter) if ord(letter) < 128 else 0\n",
    "    letter_t[i][letter_index] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "825496fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('at Mr. Darcy, “There is a fine old saying, which everybody here is of',\n",
       " ['at',\n",
       "  'mr',\n",
       "  'darcy',\n",
       "  'there',\n",
       "  'is',\n",
       "  'a',\n",
       "  'fine',\n",
       "  'old',\n",
       "  'saying',\n",
       "  'which',\n",
       "  'everybody',\n",
       "  'here',\n",
       "  'is',\n",
       "  'of'])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to do the above pre-processing for words first we clean then up\n",
    "def clean_words(input_str):\n",
    "    punctuation = '.,;:\"!?”“_-'\n",
    "    word_list = input_str.lower().replace('\\n',' ').split()\n",
    "    word_list = [word.strip(punctuation) for word in word_list]\n",
    "    return word_list\n",
    "\n",
    "words_in_line = clean_words(line)\n",
    "line, words_in_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8d6716c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#next we build a mapping of words to indexes. we do one hot accordin to this index\n",
    "word_list = sorted(set(clean_words(text))) # for alphabetical sort in index\n",
    "word2index_dict = {word: i for (i,word) in enumerate(word_list)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "534a21e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0  633 at\n",
      " 1 4305 mr\n",
      " 2 1649 darcy\n",
      " 3 6487 there\n",
      " 4 3696 is\n",
      " 5  155 a\n",
      " 6 2655 fine\n",
      " 7 4546 old\n",
      " 8 5716 saying\n",
      " 9 7084 which\n",
      "10 2384 everybody\n",
      "11 3189 here\n",
      "12 3696 is\n",
      "13 4519 of\n",
      "torch.Size([14, 7261])\n"
     ]
    }
   ],
   "source": [
    "#creating a tensor with one hot encoded words per tensor\n",
    "word_t = torch.zeros(len(words_in_line), len(word2index_dict))\n",
    "for i, word in enumerate(words_in_line):\n",
    "    word_index = word2index_dict[word]\n",
    "    word_t[i][word_index] = 1\n",
    "    print('{:2} {:4} {}'.format(i, word_index, word))\n",
    "print(word_t.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3038a59d",
   "metadata": {},
   "source": [
    "## extra exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c83c3ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_arr_red = imageio.imread(\"red.jpg\")\n",
    "img_arr_blue = imageio.imread(\"blue.jpg\")\n",
    "img_arr_green = imageio.imread(\"gree.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f0527bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "red_t = torch.from_numpy(img_arr_red)\n",
    "blue_t = torch.from_numpy(img_arr_blue)\n",
    "green_t = torch.from_numpy(img_arr_green)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "310a21f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "##pytorch requires images to be in (channel, height, width) \n",
    "##but ours is (height, width, channel) so we shuffle\n",
    "red_t = red_t.permute(2, 0, 1)\n",
    "blue_t = blue_t.permute(2, 0, 1)\n",
    "green_t = green_t.permute(2, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3b91499a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[127.8870, 253.8478, 253.7304, 253.8391, 253.8348, 252.8348, 253.7826,\n",
       "         252.8696, 253.8696, 253.8696, 253.8000, 253.8522, 253.8565, 253.8348,\n",
       "         253.8261, 253.4087, 251.6870, 250.8739, 249.0522, 248.7913, 247.8044,\n",
       "         247.4783, 247.9739, 247.0870, 242.5957, 238.0522, 238.7174, 238.1044,\n",
       "         237.4652, 237.4652, 237.5087, 237.5522, 237.1696, 235.8130, 236.3739,\n",
       "         235.8783, 234.8956, 235.8348, 236.8174, 236.7174, 235.5000, 234.6261,\n",
       "         233.9565, 234.2000, 233.9696, 233.7826, 234.2739, 235.5000, 236.0348,\n",
       "         237.1435, 237.9826, 238.5043, 239.1956, 239.3652, 239.3304, 239.4043,\n",
       "         239.0348, 239.1826, 238.6956, 238.7130, 239.4130, 239.3609, 238.8087,\n",
       "         238.6609, 238.5000, 237.6609, 236.9783, 237.0043, 236.9087, 236.2652,\n",
       "         235.8000, 235.8174, 235.0000, 234.3609, 233.7826, 233.1348, 232.5870,\n",
       "         232.1565, 231.8870, 232.0522, 232.2261, 232.0478, 231.6739, 231.2174,\n",
       "         230.8044, 230.4217, 230.3174, 230.2652, 229.9652, 230.2565, 230.4000,\n",
       "         230.4000, 230.4217, 230.4826, 230.7130, 230.8130, 230.8044, 231.1783,\n",
       "         231.6478, 231.9304, 232.1826, 232.3870, 232.5913, 232.8000, 231.7739,\n",
       "         232.1783, 232.7783, 233.1956, 233.5000, 233.8130, 234.1956, 234.4652,\n",
       "         235.1826, 234.7609, 234.6261, 235.1304, 235.4522, 235.1913, 235.6217,\n",
       "         236.3478, 236.6826, 236.6522, 236.7565, 236.8652, 237.0174, 237.0478,\n",
       "         237.4130, 237.7826, 237.4261, 237.9870, 238.7087, 238.8391, 238.9913,\n",
       "         239.1087, 239.1087, 239.1087, 239.1522, 240.0000, 240.3696, 240.3044,\n",
       "         240.3956, 241.0739, 241.8217, 242.0870, 242.8130, 242.9043, 243.3391,\n",
       "         243.8870, 244.2478, 244.0652, 244.3435, 245.3522, 245.0652, 245.6261,\n",
       "         246.0087, 246.3217, 246.0957, 246.2522, 246.7957, 247.2217, 247.2913,\n",
       "         247.2783, 247.6087, 247.7087, 247.5652, 247.5739, 248.1174, 248.7478,\n",
       "         248.7957, 249.2174, 249.3696, 249.4261, 249.6087, 249.7261, 249.8565,\n",
       "         250.1956, 250.4565, 250.7348, 250.9826, 251.3478, 251.4652, 251.8304,\n",
       "         252.0478, 253.2348, 253.8044, 253.8956, 253.7217, 252.9391, 253.6304,\n",
       "         252.9478, 127.9217],\n",
       "        [127.8870, 253.8478, 253.7304, 253.8391, 253.8348, 252.8348, 253.7826,\n",
       "         252.8696, 253.8696, 253.8696, 253.8000, 253.8522, 253.8565, 253.8348,\n",
       "         253.8261, 253.4087, 250.1217, 249.1565, 247.0696, 246.7217, 245.5870,\n",
       "         245.5087, 246.1522, 245.2174, 229.7130, 204.3478, 197.3044, 193.7739,\n",
       "         187.1044, 182.1044, 179.5696, 175.7783, 172.4000, 169.0739, 167.0739,\n",
       "         164.2043, 160.9957, 159.4783, 157.5174, 155.0000, 152.4174, 150.3000,\n",
       "         147.3478, 144.8217, 142.7522, 141.2087, 139.7174, 138.9478, 138.2652,\n",
       "         138.1478, 137.1174, 136.2261, 136.1609, 136.7957, 137.5000, 138.1130,\n",
       "         138.1826, 138.0957, 137.1739, 136.3956, 135.9739, 134.5739, 132.7522,\n",
       "         131.9130, 130.7391, 129.7217, 128.7435, 128.2826, 127.6348, 126.2652,\n",
       "         125.2348, 124.8130, 123.7696, 123.1174, 122.5739, 121.8478, 121.1217,\n",
       "         120.4348, 119.8130, 119.8435, 119.2000, 118.9826, 118.5478, 118.0826,\n",
       "         117.7565, 117.6304, 117.7043, 117.7783, 117.8652, 118.0087, 118.0478,\n",
       "         117.9435, 117.8913, 118.1130, 118.4217, 118.6304, 119.1783, 119.5348,\n",
       "         119.8130, 119.9739, 120.0217, 120.0609, 120.1565, 120.2783, 121.5478,\n",
       "         122.0348, 122.6261, 123.2174, 123.5826, 124.0565, 124.4739, 124.8304,\n",
       "         125.9217, 125.8609, 126.6565, 128.0261, 128.9609, 129.3826, 130.0174,\n",
       "         130.8304, 131.5739, 131.8652, 132.5783, 133.5217, 134.2739, 134.9391,\n",
       "         135.5913, 136.1522, 136.8783, 137.5913, 138.8391, 139.6783, 140.3870,\n",
       "         141.1609, 141.4217, 141.6696, 143.1087, 144.3044, 145.4522, 146.3304,\n",
       "         147.5043, 149.2261, 150.8044, 151.5217, 153.5304, 154.2913, 155.6478,\n",
       "         157.6087, 159.4043, 160.4565, 161.8652, 163.4609, 165.4826, 166.4826,\n",
       "         168.2000, 169.9522, 171.6870, 173.2522, 175.0739, 176.4043, 178.1739,\n",
       "         179.5565, 181.7696, 183.8130, 185.5435, 187.6044, 190.1870, 192.0391,\n",
       "         194.8609, 197.6000, 200.7261, 203.1652, 205.6652, 208.5261, 211.5826,\n",
       "         213.7261, 216.7217, 219.8609, 222.5739, 224.8956, 231.6609, 239.5261,\n",
       "         246.0478, 253.1348, 253.8044, 253.8956, 253.7217, 252.9391, 253.6304,\n",
       "         252.9478, 127.9217],\n",
       "        [127.8870, 253.8478, 253.7304, 253.8391, 253.8348, 252.8348, 253.7826,\n",
       "         252.8696, 253.8696, 253.8696, 253.8000, 253.8522, 253.8565, 253.8348,\n",
       "         253.8261, 253.4087, 249.4435, 248.4696, 246.1739, 245.6739, 244.9000,\n",
       "         245.2304, 245.9870, 245.2522, 228.0696, 203.0043, 193.0565, 188.5130,\n",
       "         181.5261, 175.7609, 172.6087, 169.5348, 164.5130, 161.3087, 159.0913,\n",
       "         156.0652, 152.5652, 150.6652, 148.3261, 145.4696, 142.8652, 140.7391,\n",
       "         137.7391, 135.2783, 132.7783, 130.8913, 129.4261, 128.7826, 127.6826,\n",
       "         127.8391, 127.4000, 126.7696, 127.0261, 127.6000, 127.9957, 128.8435,\n",
       "         128.5000, 128.4087, 127.4391, 126.7000, 126.4087, 125.3522, 123.9391,\n",
       "         123.3652, 121.9391, 120.8130, 119.6000, 119.0783, 118.3348, 117.0739,\n",
       "         116.2261, 115.9522, 114.2957, 113.5826, 112.8826, 112.0174, 110.9174,\n",
       "         110.1130, 109.4304, 109.3609, 108.5043, 108.2913, 107.8478, 107.4044,\n",
       "         107.0217, 106.8043, 106.8087, 106.8435, 106.4870, 106.6304, 106.6913,\n",
       "         106.6304, 106.6217, 106.7783, 107.0826, 107.2739, 107.6957, 108.0522,\n",
       "         108.4130, 108.6652, 108.7696, 108.8870, 109.0478, 109.2348, 110.3174,\n",
       "         110.8000, 111.3739, 111.9565, 112.4044, 112.8609, 113.3174, 113.6565,\n",
       "         114.4870, 114.3478, 114.9696, 116.1652, 117.0696, 117.4174, 118.1043,\n",
       "         118.9304, 119.8739, 120.0565, 120.5304, 121.1348, 121.5956, 121.9522,\n",
       "         122.4783, 122.9913, 123.5913, 124.3696, 125.4435, 126.2087, 127.0609,\n",
       "         127.8000, 128.4478, 128.7478, 129.3913, 130.6261, 131.7435, 132.5217,\n",
       "         133.5826, 134.9130, 136.3261, 136.9913, 138.9304, 139.6391, 141.0435,\n",
       "         142.9609, 144.5739, 145.6217, 146.7261, 148.3609, 150.7957, 151.9957,\n",
       "         153.8217, 155.8826, 157.7304, 159.6174, 161.5130, 162.8783, 165.4783,\n",
       "         166.8044, 169.2261, 171.9391, 173.8783, 176.5609, 179.2348, 181.0478,\n",
       "         184.8696, 187.3652, 190.8435, 193.8783, 197.1913, 200.4348, 203.5783,\n",
       "         205.8609, 210.2478, 213.2348, 215.5522, 218.6522, 226.4000, 235.0087,\n",
       "         243.4739, 252.4261, 253.8044, 253.8956, 253.7217, 252.9391, 253.6304,\n",
       "         252.9478, 127.9217]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float_img = torch.Tensor.float(red_t)\n",
    "torch.mean(float_img, dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2daa9f63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
